# Q-A-CHAT-with_PDF-LocalLLM

#Instruction to run the app 
# Step 1: Create a virtual Environment for python.
# Step 2: install dependencies by running."pip install -r requirements.txt"
# Step 3: Install Ollama locally and run "ollama run llama3.2"
# step 4: start the app by "streamlit run app.py"
# Step 5: Load the documnet submit and process then ask questions about it.
# Thank you 
# Mayank Rajput.
